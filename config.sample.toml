# Borg Agent Configuration Template
# Copy this file to config.toml and add your API keys:
#   cp config.sample.toml config.toml
# The config.toml file is ignored by Git to prevent accidentally committing your API keys.

# Default LLM configuration (used as fallback)
[llm.default]
provider = "openrouter"
api_key = "your-openrouter-api-key-here"  # Or set OPENROUTER_API_KEY env var
model = "openrouter/auto"
max_tokens = 2048
temperature = 0.0
api_base = "https://openrouter.ai/api/v1"
# Optional headers for OpenRouter (uncomment to use)
# [llm.default.headers]
# HTTP-Referer = "https://your.app"
# X-Title = "Your App Name"

# Code Generation LLM (specialized for writing high-quality code)
[llm.code_generation]
provider = "anthropic"
api_key = "your-anthropic-api-key-here"
model = "claude-3-7-sonnet-20250219"  # High-capability model for code
max_tokens = 4096                     # Larger token limit for code generation
temperature = 0.0                     # Lower temperature for more deterministic output

# Ethical Assessment LLM (specialized for evaluating ethical implications)
[llm.ethics]
provider = "anthropic"
api_key = "your-anthropic-api-key-here"
model = "claude-3-7-opus-20240229"    # Most capable model for ethical reasoning
max_tokens = 1024
temperature = 0.0                     # Low temperature for consistent ethical judgments

# Planning LLM (for goal selection and high-level planning)
[llm.planning]
provider = "anthropic"
api_key = "your-anthropic-api-key-here"
model = "claude-3-7-sonnet-20250219"
max_tokens = 2048
temperature = 0.5                     # Medium temperature for creative but coherent planning

# Code Review LLM (for validating and reviewing code changes)
[llm.code_review]
provider = "anthropic"
api_key = "your-anthropic-api-key-here"
model = "claude-3-7-haiku-20250209"   # Faster model suitable for review tasks
max_tokens = 1536
temperature = 0.0                     # Lower temperature for consistent code reviews

[agent]
max_memory_usage_mb = 2048
max_cpu_usage_percent = 80
working_dir = "./workspace"
timeout_seconds = 120
testing_mode = false                  # When true, prevents recursive agent activation

[git]
repo_url = ""                         # Leave empty for local-only repository
username = ""                         # Optional: For remote repository auth
token = ""                            # Optional: For remote repository auth
branch_prefix = "borg/improvement/"

[testing]
linting_enabled = true                # Enable code linting
compilation_check = true              # Verify code compiles before merging
run_unit_tests = true                 # Run unit tests on changes
run_integration_tests = false         # Run integration tests (more time-consuming)
performance_benchmarks = false        # Run performance benchmarks
timeout_seconds = 300                 # Timeout for test execution

[llm_logging]
enabled = true
log_dir = "./logs/llm"
console_logging = true
include_full_prompts = true
include_full_responses = true
max_log_size_mb = 100
log_files_to_keep = 10

[mongodb]
enabled = false                       # Set to true to use MongoDB instead of file-based storage
connection_string = "mongodb://localhost:27017"  # Local MongoDB for development
database = "borg"                     # Database name

# üîê SECURITY CONFIGURATION
# This section configures the authentication system that fixes the critical security vulnerability
[authentication]
# IMPORTANT: Generate strong, unique API keys for production use
# Example generation: openssl rand -hex 32
api_keys = [
    "your-secure-api-key-here-replace-with-actual-key",
    # Add additional API keys as needed for different users/services
    # "another-api-key-for-service-account",
]

# Code generation configuration
[code_generation]
candidate_count = 1          # Number of parallel candidates (1 for MVP)
max_retries = 3              # Retry attempts if all candidates fail
use_worktrees = true         # Use git worktrees for isolation
rating_enabled = false       # Enable multi-LLM rating (false for MVP)
tdd_enabled = true           # Enable TDD flow: spec ‚Üí tests ‚Üí implement
max_implementation_retries = 3  # Retries for implementation (tests stay fixed)

# Session configuration
session_timeout_seconds = 3600        # 1 hour session timeout
max_sessions_per_key = 5              # Maximum concurrent sessions per API key
session_cleanup_interval_seconds = 300 # Clean up expired sessions every 5 minutes

# Rate limiting (prevents abuse)
rate_limit_per_minute = 100           # Requests per minute per API key

# Security policies
require_authentication = true         # CRITICAL: Must be true for production
default_role = "Developer"            # Options: "User", "Developer", "Administrator", "Creator"

# Failed authentication protection
max_failed_attempts = 5               # Lock out after 5 failed attempts
lockout_duration_seconds = 900        # 15 minute lockout period

# Audit logging
log_auth_events = true                # Log all authentication events
auth_log_dir = "./logs/auth"         # Directory for authentication logs

# -----------------------------------------------------------------------------
# Example: OpenAI provider (commented-out)
# -----------------------------------------------------------------------------
# [llm.default]
# provider = "openai"
# api_key = "your-openai-api-key-here"
# model = "gpt-4o"
# max_tokens = 2048
# temperature = 0.0